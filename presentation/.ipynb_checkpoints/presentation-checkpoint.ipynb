{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Twitter NER with Neural Nets\n",
    "\n",
    "#### Jovana Urosevic & Kenny Lino\n",
    "##### March 15, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "#### 1.  Task and Motivation\n",
    "#### 2.  Data\n",
    "#### 3.  Baseline\n",
    "#### 4.  Experiment\n",
    "#### 5.  Results\n",
    "#### 6.  Conclusion and Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Task of Named entity recognition is the task of trying to isolate mentions of specific kinds of people, places, organisations and things in unstructured text. In general, tools such as Stanford CoreNLP can do a very good job of this for formal, well-edited text such as newspaper articles. Traditionally, most of the effective NER approaches are based on machine learning techniques, such as conditional random field (CRF), support vector machine (SVM), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is NER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![pic](pic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "However, a lot of the data comes from social media that we need to be able to process, in particular Twitter. Tweets are full of informal language, misspellings, abbreviations, hashtags, @-mentions, URLs, and unreliable capitalization and punctuation. Also, users can talk about anything and everything on Twitter, and new entities that were never or scarcely mentioned ever before may become suddenly popular. Also,  tweets are typically short as the number of characters in a particular tweet is restricted to 140. All these factors present huge challenges for general-purpose NER systems that were not designed for this type of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why NER on Twitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic1](1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![pic2](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Shared Task -  COLING 2016 Workshop on Noisy User-generated text (WNUT):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Segmentation and categorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Segmentation only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Represented using the ConLL data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Sentence   |Label|\n",
    "|-------------|:---------:|\n",
    "|It |O|\n",
    "|sucks |O|\n",
    "|not|O|\n",
    "|to|O|\n",
    "|be|O|\n",
    "|in|O|\n",
    "|Disney |**B-facility**|\n",
    "|world|**I-facility**|\n",
    "|. |O|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- annotation\n",
    "The Twitter NER shared task datasets consist of training set,  development set and test set. The numbers of tweets and tokens of each set are shown in Table. The shared task focuses on finding 10 types of target entities, including company, facility, geo-location, movie, music-artist, other, person, product, sport team and TV show. In particular, the shared task can be divided into two sub-tasks: ‘segmentation only’ and ‘segmentation and categorisation’. The former focuses only on finding the boundaries of entities; meanwhile, the latter requires both the boundaries of entities and the correct categories of entity types.\n",
    "- 21 tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "10 fine-grained NER categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Label type|Train|Dev|Test|\n",
    "|-------------|---------|------|--------|\n",
    "|company|171|39|621|\n",
    "|facility|104|38|253|\n",
    "|geo-loc|276|116|882|\n",
    "|movie|34|15|34|\n",
    "|music artist|55|41|191|\n",
    "|other|225|132|584|\n",
    "|person|449|171|482|\n",
    "|product|97|37|246|\n",
    "|sports team|51|70|147|\n",
    "|tv show|34|2|33|\n",
    "|Total|1496|1420|3473|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Conditional random field (CRF) is one of the most effective approaches for NER, as it achieved state-of-the-art performances on several NER tasks. In particular, CRF learns latent structures of an input sequence by using a undirected statistical graphical model. Nevertheless, the performance of CRF mainly depends on hand-crafted features designed specifically for a particular task or domain. Consequently, these hand-crafted features are difficult to develop and maintain. Examples of hand-crafted features are orthographic features, which are based on patterns of characters contained in a given word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using Conditional Random Fields (CRFs) to label data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Label type   |Precision|Recall|F1 score|# of phrases|\n",
    "|-------------|---------|------|--------|------------|\n",
    "|company|35.48|28.21|31.43| 31|\n",
    "|facility|15.79|15.79|15.79|38|\n",
    "|geo-loc|47.69|53.45|50.41|130|\n",
    "|movie|0.00|0.00|0.00|8|\n",
    "|music artist|0.00|0.00|0.00|4|\n",
    "|other|33.33|22.73|27.03|90|\n",
    "|person|52.04|59.65|55.59|196|\n",
    "|product|7.14|2.70|3.92|14|\n",
    "|sports team|40.00|8.57|14.12|15|\n",
    "|tv show|0.00|0.00|0.00|6|\n",
    "|**AVG**|40.98|32.98|36.55|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Accuracy:  93.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WNUT 2016 - Winning system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![3pic](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Label type  |   Precision | Recall  |  F1       |\n",
    "| -------- | ----------| ----------- | ------- | \n",
    "| company | 69.84 | 48.47 |57.22 |\n",
    "| facility | 51.70 | 35.97 |42.42 |\n",
    "| geo-loc |75.21 | 70.18 | 72.61 | \n",
    "| movie | 14.29 | 8.82 | 10.91 |\n",
    "| musicartist | 26.83 | 5.76 | 9.48 |\n",
    "| other | 49.45 | 23.29 | 31.66 |\n",
    "| person | 52.06 | 68.05 | 58.99 |\n",
    "| product | 36.96 | 13.82 | 20.12 |\n",
    "| sportsteam | 53.15 | 51.70 | 52.41 |\n",
    "| tvshow | 100.00 | 3.03 | 5.88 |\n",
    "| **AVG** | 60.77 | 46.07 | 52.41 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment 1 - Word-based biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Embeddings from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Combining train + dev -> test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Label type  |   Precision | Recall  |  F1       | # of phrases|\n",
    "| -------- | ----------| ----------- | ------- |------|\n",
    "|company |3.27|17.53|15.10|844|\n",
    "|facility|17.37|16.92|17.14|259|\n",
    "|geo-loc|48.31|35.40|40.86|650|\n",
    "|movie|0.00|0.00|0.00|123|\n",
    "|musicartist|16.67|2.55|4.42|30|\n",
    "|other|31.46|15.22|20.52|302|\n",
    "|person|25.43|14.74|18.66|291|\n",
    "|product|5.40|5.28|5.34|278|\n",
    "|sportsteam|5.42|11.92|7.45|332|\n",
    "|tvshow|0.00|0.00|0.00|73|\n",
    "|**AVG**|21.31|18.72|19.93|3182|\n",
    "\n",
    "Accuracy: 89.90%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* GloVe (2B tweets, 1.2M vocab,  200d vectors)\n",
    "* Godin et al. (2015) (400M tweets, 3M vocab, 400d vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment 2 - Character-based biLSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gif2](gif2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Our orthographic sentence generator creates an orthographic sentence, which contains orthographic pattern of words in each input sentence. In particular, for a given social media sentence (e.g. ‘14th MENA FOREX EXPO announced!!’), we generate an orthographic sentence (e.g. ‘nncc CCCC CCCCC CCCC cccccccccpp’) by using a set of rules, where each of the upper-case characters, lower-case characters, numbers and punctuations, are replaced with C, c, n and p, respectively. Examples of orthographic sentences generated from social media sentences are shown in Table 1. This orthographic sentence allows bidirectional LSTM to explicitly induce and leverage orthographic features automatically.\n",
    "We focus on orthographic features as they have shown to be effective and widely used in several NER systems. Importantly, orthographic features are used by majority of the systems (including the best system) participating in the Twitter NER shared task at the 2015 WNUT workshop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use  orthographic features: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "14th MENA FOREX EXPO announced!! <br>\n",
    "\n",
    "nncc CCCC CCCCC CCCC cccccccccpp <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### address inconsistencies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](tweet-example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](tweet-example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](tweet-example3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](tweet-example4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion \n",
    "![gif](gif.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Benjamin Strauss, Bethany E. Toma, Alan Ritter, Marie-Catherine de Marneffe, Wei Xu. \"Results of the WNUT16 Named Entity Recognition Shared Task.\" NUT@COLING (2016) <br>\n",
    "2. Limsopatham, Nut and Nigel Collier. “Bidirectional LSTM for Named Entity Recognition in Twitter Messages.” NUT@COLING (2016). <br>\n",
    "3. WNUT Named Entity Recognition in Twitter Shared task: https://github.com/aritter/twitter_nlp/tree/master/data/anntated/wnut16 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
