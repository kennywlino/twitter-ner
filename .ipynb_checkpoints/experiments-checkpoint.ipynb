{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses an embedding representation of the words in the vocabulary which is then passed through a BiLSTM to predict the NER labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines dicts to convert words and tags into indices\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2w(index):\n",
    "    \"\"\"Takes a word index and returns word.\"\"\" \n",
    "    return list(w2i.keys())[list(w2i.values()).index(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2t(index):\n",
    "    \"\"\"Takes a tag index and returns a tag.\"\"\"\n",
    "    return list(t2i.keys())[list(t2i.values()).index(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    \"\"\"Reads a file from the WNUT17 dataset.\n",
    "\n",
    "    Returns:\n",
    "        A list containing each sentence from the dataset in a separate list.\n",
    "        Each element inside the sentence list is a tuple containing the\n",
    "        word index and tag index.\n",
    "        \n",
    "    For example:\n",
    "    [[(1, 0), (2, 1), (3, 1), (4, 0)],[(2,1), (13,1), (14, 0), (15,0)]]\n",
    "\"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        data_list = []\n",
    "        sent_list = []\n",
    "        for line in f:\n",
    "            if len(line.strip()) != 0:\n",
    "                word, tag = line.strip().split(\"\\t\")\n",
    "                sent_list.append((w2i[word], t2i[tag])) # (word index, tag index)\n",
    "            else:\n",
    "                if len(sent_list) != 0:\n",
    "                    data_list.append(sent_list)\n",
    "                sent_list = []\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the training and dev data; combines them both as train\n",
    "train = read_dataset(\"wnut17/data/train\")\n",
    "dev = read_dataset(\"wnut17/data/dev\")\n",
    "train = train + dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezes the w2i dict\n",
    "w2i = defaultdict(lambda: UNK, w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words and number of tags\n",
    "nwords = max(w2i.values()) + 1 # used to exclude extra UNK\n",
    "ntags = len(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the test data;\n",
    "test = read_dataset(\"wnut17/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "EMB_SIZE = 64\n",
    "HID_SIZE = 64\n",
    "W_emb = model.add_lookup_parameters((nwords, EMB_SIZE))  # Word embeddings\n",
    "lstm_builders = [dy.LSTMBuilder(1, EMB_SIZE, HID_SIZE, model), \n",
    "                 dy.LSTMBuilder(1, EMB_SIZE, HID_SIZE, model)] # fwd and bwd LSTM\n",
    "W_sm = model.add_parameters((ntags, 2 * HID_SIZE))  # Softmax weights\n",
    "b_sm = model.add_parameters((ntags))  # Softmax bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagging_graph(sent):\n",
    "    \"\"\"\n",
    "    Builds the comp graph for the model with:\n",
    "    * Embeddings\n",
    "    * BiLSTM\n",
    "    @return list of error for each tag\n",
    "    \"\"\"\n",
    "    dy.renew_cg()\n",
    "    fwd_init, bwd_init = [b.initial_state() for b in lstm_builders]\n",
    "    word_embs = [dy.lookup(W_emb, word) for word, tag in sent]\n",
    "    \n",
    "    fwd_embs = [x.output() for x in fwd_init.add_inputs(word_embs)]\n",
    "    bwd_embs = [x.output() for x in bwd_init.add_inputs(reversed(word_embs))]\n",
    "    \n",
    "    W_sm_exp = dy.parameter(W_sm)\n",
    "    b_sm_exp = dy.parameter(b_sm)\n",
    "    \n",
    "    errs = []\n",
    "    for (word, tag), f_rep, b_rep in zip(sent, fwd_embs, reversed(bwd_embs)):\n",
    "        complete_rep = dy.concatenate([f_rep, b_rep]) # complete rep of a single word from LSTM\n",
    "        predicted = W_sm_exp * complete_rep + b_sm_exp\n",
    "        err = dy.pickneglogsoftmax(predicted, tag)\n",
    "        errs.append(err)\n",
    "    return dy.esum(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sent(sent):\n",
    "    \"\"\"\n",
    "    Builds the comp graph for the model with:\n",
    "    * Embeddings\n",
    "    * BiLSTM\n",
    "    @ return list of (word, predicted labels)\n",
    "    \"\"\"\n",
    "    dy.renew_cg()\n",
    "    fwd_init, bwd_init = [b.initial_state() for b in lstm_builders]\n",
    "    word_embs = [dy.lookup(W_emb, word) for word, tag in sent]\n",
    "    \n",
    "    fwd_embs = [x.output() for x in fwd_init.add_inputs(word_embs)]\n",
    "    bwd_embs = [x.output() for x in bwd_init.add_inputs(reversed(word_embs))]\n",
    "    \n",
    "    W_sm_exp = dy.parameter(W_sm)\n",
    "    b_sm_exp = dy.parameter(b_sm)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for (word, tag), f_rep, b_rep in zip(sent, fwd_embs, reversed(bwd_embs)):\n",
    "        complete_rep = dy.concatenate([f_rep, b_rep]) # complete rep of word from LSTM\n",
    "        scores = (W_sm_exp * complete_rep + b_sm_exp).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        predicted_labels.append((word, predict))\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: train loss/sent=7.5517, time=8.21s\n",
      "iter 0: test acc=0.9074\n",
      "iter 1: train loss/sent=5.2902, time=7.98s\n",
      "iter 1: test acc=0.9094\n",
      "iter 2: train loss/sent=4.2207, time=8.31s\n",
      "iter 2: test acc=0.9097\n",
      "iter 3: train loss/sent=3.4515, time=11.40s\n",
      "iter 3: test acc=0.9044\n",
      "iter 4: train loss/sent=2.7430, time=8.51s\n",
      "iter 4: test acc=0.9031\n",
      "iter 5: train loss/sent=2.1375, time=7.76s\n",
      "iter 5: test acc=0.8933\n",
      "iter 6: train loss/sent=1.5983, time=7.73s\n",
      "iter 6: test acc=0.9006\n",
      "iter 7: train loss/sent=1.1494, time=7.75s\n",
      "iter 7: test acc=0.9013\n",
      "iter 8: train loss/sent=0.7974, time=7.76s\n",
      "iter 8: test acc=0.9004\n",
      "iter 9: train loss/sent=0.5201, time=7.71s\n",
      "iter 9: test acc=0.8925\n",
      "iter 10: train loss/sent=0.3400, time=7.75s\n",
      "iter 10: test acc=0.8865\n",
      "iter 11: train loss/sent=0.2171, time=7.75s\n",
      "iter 11: test acc=0.8954\n",
      "iter 12: train loss/sent=0.1543, time=10.27s\n",
      "iter 12: test acc=0.8942\n",
      "iter 13: train loss/sent=0.1269, time=9.14s\n",
      "iter 13: test acc=0.8823\n",
      "iter 14: train loss/sent=0.0966, time=7.76s\n",
      "iter 14: test acc=0.8772\n",
      "iter 15: train loss/sent=0.1014, time=7.72s\n",
      "iter 15: test acc=0.8979\n",
      "iter 16: train loss/sent=0.0886, time=8.22s\n",
      "iter 16: test acc=0.8975\n",
      "iter 17: train loss/sent=0.0859, time=9.38s\n",
      "iter 17: test acc=0.8871\n",
      "iter 18: train loss/sent=0.0861, time=8.07s\n",
      "iter 18: test acc=0.8914\n",
      "iter 19: train loss/sent=0.0913, time=7.94s\n",
      "iter 19: test acc=0.8930\n",
      "iter 20: train loss/sent=0.0731, time=9.68s\n",
      "iter 20: test acc=0.9022\n",
      "iter 21: train loss/sent=0.0735, time=9.00s\n",
      "iter 21: test acc=0.9030\n",
      "iter 22: train loss/sent=0.0751, time=8.33s\n",
      "iter 22: test acc=0.9048\n",
      "iter 23: train loss/sent=0.0741, time=8.85s\n",
      "iter 23: test acc=0.8976\n",
      "iter 24: train loss/sent=0.0687, time=7.87s\n",
      "iter 24: test acc=0.8993\n",
      "iter 25: train loss/sent=0.0689, time=8.47s\n",
      "iter 25: test acc=0.9061\n",
      "iter 26: train loss/sent=0.0679, time=7.87s\n",
      "iter 26: test acc=0.8939\n",
      "iter 27: train loss/sent=0.0640, time=8.07s\n",
      "iter 27: test acc=0.9073\n",
      "iter 28: train loss/sent=0.0572, time=8.37s\n",
      "iter 28: test acc=0.9071\n",
      "iter 29: train loss/sent=0.0629, time=8.91s\n",
      "iter 29: test acc=0.9061\n",
      "iter 30: train loss/sent=0.0553, time=9.33s\n",
      "iter 30: test acc=0.9028\n",
      "iter 31: train loss/sent=0.0624, time=8.97s\n",
      "iter 31: test acc=0.8965\n",
      "iter 32: train loss/sent=0.0577, time=8.60s\n",
      "iter 32: test acc=0.9051\n",
      "iter 33: train loss/sent=0.0574, time=8.34s\n",
      "iter 33: test acc=0.9087\n",
      "iter 34: train loss/sent=0.0514, time=8.06s\n",
      "iter 34: test acc=0.9090\n",
      "iter 35: train loss/sent=0.0486, time=8.58s\n",
      "iter 35: test acc=0.9103\n",
      "iter 36: train loss/sent=0.0496, time=8.69s\n",
      "iter 36: test acc=0.9075\n",
      "iter 37: train loss/sent=0.0470, time=9.18s\n",
      "iter 37: test acc=0.9070\n",
      "iter 38: train loss/sent=0.0476, time=8.78s\n",
      "iter 38: test acc=0.9007\n",
      "iter 39: train loss/sent=0.0469, time=8.11s\n",
      "iter 39: test acc=0.8969\n",
      "iter 40: train loss/sent=0.0446, time=8.17s\n",
      "iter 40: test acc=0.9034\n",
      "iter 41: train loss/sent=0.0468, time=8.14s\n",
      "iter 41: test acc=0.9038\n",
      "iter 42: train loss/sent=0.0458, time=7.85s\n",
      "iter 42: test acc=0.8966\n",
      "iter 43: train loss/sent=0.0416, time=9.46s\n",
      "iter 43: test acc=0.9040\n",
      "iter 44: train loss/sent=0.0414, time=8.76s\n",
      "iter 44: test acc=0.9062\n",
      "iter 45: train loss/sent=0.0400, time=7.80s\n",
      "iter 45: test acc=0.9071\n",
      "iter 46: train loss/sent=0.0368, time=7.83s\n",
      "iter 46: test acc=0.8983\n",
      "iter 47: train loss/sent=0.0412, time=8.22s\n",
      "iter 47: test acc=0.8987\n",
      "iter 48: train loss/sent=0.0366, time=8.03s\n",
      "iter 48: test acc=0.9051\n",
      "iter 49: train loss/sent=0.0410, time=8.37s\n",
      "iter 49: test acc=0.9003\n"
     ]
    }
   ],
   "source": [
    "iter_max = 50 # max num. of iterations\n",
    "\n",
    "for ITER in range(iter_max):\n",
    "    \"\"\"\n",
    "    Trains a neural network using the defined computational graph.\n",
    "    Prints the accuracy per iteration and outputs the predictions in the final\n",
    "    iteration.\n",
    "    \n",
    "    Args:\n",
    "        iter_max: the maximum number of iterations to train the network.\n",
    "    \"\"\"\n",
    "    # Perform training\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    if ITER == iter_max - 1: # final iteration\n",
    "        out = open('baseline-nn.txt', 'w')\n",
    "    for sent in train:\n",
    "        sent_error = build_tagging_graph(sent)\n",
    "        train_loss += sent_error.value()\n",
    "        sent_error.backward()\n",
    "        trainer.update()\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss / len(train), time.time() - start))\n",
    "    \n",
    "    total_acc = 0.0\n",
    "    for sent in test:\n",
    "        p_labels = tag_sent(sent)\n",
    "        g_labels = [tags for word, tags in sent]\n",
    "        test_correct = 0\n",
    "        for i, p_g in enumerate(zip(p_labels, g_labels)):\n",
    "            word = p_g[0][0]\n",
    "            predicted = p_g[0][1]\n",
    "            gold = p_g[1]\n",
    "            if predicted == gold:\n",
    "                test_correct += 1\n",
    "            if ITER == iter_max - 1:\n",
    "                out.write(i2w(word) + '\\t' + i2t(gold) + '\\t' + i2t(predicted) + '\\n') # writes the word, gold tag, and predicted tag\n",
    "                if i == (len(p_g) - 1):\n",
    "                    out.write('\\n')\n",
    "        total_acc += test_correct / len(g_labels)\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, total_acc / len(test)))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 61908 tokens with 3621 phrases; found: 3206 phrases; correct: 631.\n",
      "accuracy:  89.80%; precision:  19.68%; recall:  17.43%; FB1:  18.49\n",
      "          company: precision:  14.66%; recall:  17.68%; FB1:  16.03  771\n",
      "         facility: precision:  12.34%; recall:  10.90%; FB1:  11.58  235\n",
      "          geo-loc: precision:  43.78%; recall:  29.76%; FB1:  35.44  603\n",
      "            movie: precision:   0.00%; recall:   0.00%; FB1:   0.00  161\n",
      "      musicartist: precision:  13.04%; recall:   1.53%; FB1:   2.74  23\n",
      "            other: precision:  19.18%; recall:  14.90%; FB1:  16.77  485\n",
      "           person: precision:  14.32%; recall:  21.31%; FB1:  17.13  747\n",
      "          product: precision:  17.39%; recall:   5.63%; FB1:   8.51  92\n",
      "       sportsteam: precision:  10.00%; recall:   3.97%; FB1:   5.69  60\n",
      "           tvshow: precision:   0.00%; recall:   0.00%; FB1:   0.00  29\n"
     ]
    }
   ],
   "source": [
    "# runs conll evaluation script; minor change for python3 in file (line 155)\n",
    "!python3 conlleval.py predicted/baseline-nn.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the 200 dimension pre-trained Glove embeddings to represent the words which are then passed through the BiLSTM to predict the NER labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a word index and returns word\n",
    "def i2w(index):\n",
    "    return list(w2i.keys())[list(w2i.values()).index(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a tag index and returns tag\n",
    "def i2t(index):\n",
    "     return list(t2i.keys())[list(t2i.values()).index(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data_list = []\n",
    "        sent_list = []\n",
    "        for line in f:\n",
    "            if len(line.strip()) != 0:\n",
    "                word, tag = line.strip().split(\"\\t\")\n",
    "                sent_list.append((word, t2i[tag]))\n",
    "            else:\n",
    "                if len(sent_list) != 0:\n",
    "                    data_list.append(sent_list)\n",
    "                sent_list = []\n",
    "        return data_list\n",
    "\n",
    "# [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0), (8, 0), (9, 0), (10, 1), (11, 0), (12, 0), (13, 0), (14, 0), (15, 0), (16, 0), (17, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = read_dataset(\"wnut17/data/dev\")\n",
    "train = read_dataset(\"wnut17/data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: UNK, w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_dataset(\"wnut17/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = len(w2i)\n",
    "ntags = len(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the pre-trained Glove embeddings\n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "vectors = []\n",
    "vectors.append(list(np.zeros(200))) # 200 zeros or random?\n",
    "with open(\"glove.twitter.27B/glove.twitter.27B.200d.txt\") as f:\n",
    "    f.readline()\n",
    "    for i, line in enumerate(f):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        fields = line.strip().split(\" \")\n",
    "        vocab[fields[0]]\n",
    "        vectors.append(list(map(float, fields[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dy.Model()\n",
    "lookup = model.add_lookup_parameters((len(vectors), len(vectors[0])))\n",
    "lookup.init_from_array(np.array(vectors))\n",
    "print(lookup[vocab[\"hello\"]].value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagging_graph(sent):\n",
    "    dy.renew_cg()\n",
    "    fwd_init, bwd_init = [b.initial_state() for b in lstm_builders]\n",
    "    word_embs = [dy.lookup(W_emb, word) for word, tag in sent]\n",
    "    \n",
    "    fwd_embs = [x.output() for x in fwd_init.add_inputs(word_embs)]\n",
    "    bwd_embs = [x.output() for x in bwd_init.add_inputs(reversed(word_embs))]\n",
    "    \n",
    "    W_sm_exp = dy.parameter(W_sm)\n",
    "    b_sm_exp = dy.parameter(b_sm)\n",
    "    \n",
    "    errs = []\n",
    "    for (word, tag), f_rep, b_rep in zip(sent, fwd_embs, reversed(bwd_embs)):\n",
    "        complete_rep = dy.concatenate([f_rep, b_rep]) # complete rep of word from LSTM\n",
    "        predicted = W_sm_exp * complete_rep + b_sm_exp\n",
    "        err = dy.pickneglogsoftmax(predicted, tag)\n",
    "        errs.append(err)\n",
    "    return dy.esum(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sent(sent):\n",
    "    dy.renew_cg()\n",
    "    fwd_init, bwd_init = [b.initial_state() for b in lstm_builders]\n",
    "    word_embs = [dy.lookup(W_emb, word, update=False) for word, tag in sent]\n",
    "    \n",
    "    fwd_embs = [x.output() for x in fwd_init.add_inputs(word_embs)]\n",
    "    bwd_embs = [x.output() for x in bwd_init.add_inputs(reversed(word_embs))]\n",
    "    \n",
    "    W_sm_exp = dy.parameter(W_sm)\n",
    "    b_sm_exp = dy.parameter(b_sm)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for (word, tag), f_rep, b_rep in zip(sent, fwd_embs, reversed(bwd_embs)):\n",
    "        complete_rep = dy.concatenate([f_rep, b_rep]) # complete rep of word from LSTM\n",
    "        scores = (W_sm_exp * complete_rep + b_sm_exp).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        predicted_labels.append(predict)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ITER in range(50):\n",
    "    # Perform training\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    for sent in train:\n",
    "        sent_error = build_tagging_graph(sent)\n",
    "        train_loss += sent_error.value()\n",
    "        sent_error.backward()\n",
    "        trainer.update()\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss / len(train), time.time() - start))\n",
    "    total_acc = 0.0\n",
    "    for sent in dev:\n",
    "        p_labels = tag_sent(sent)\n",
    "        g_labels = [tags for word, tags in sent]\n",
    "        test_correct = 0\n",
    "        for predicted, gold in zip(p_labels, g_labels):\n",
    "            if predicted == gold:\n",
    "                test_correct += 1\n",
    "        total_acc += test_correct / len(g_labels)\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, total_acc / len(dev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
